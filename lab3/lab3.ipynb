{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#文本分类任务：数据预处理\nimport pandas as pd\ndf = pd.read_csv('/kaggle/input/online-shopping-10-cats/online_shopping_10_cats.csv')#将逗号分隔值（csv）文件读取到DataFrame中\ndf=df[['cat','review']] #id为该评论所属类别 review为评论具体内容\nprint(\"数据总量: %d .\" % len(df))\ndf.sample(10)#对数据集进行抽样查看\nprint(\"在 cat 列中总共有 %d 个空值.\" % df['cat'].isnull().sum())#查看cat列的空值\nprint(\"在 review 列中总共有 %d 个空值.\" % df['review'].isnull().sum())\ndf[df.isnull().values==True]#isnull返回一个布尔数组\ndf = df[pd.notnull(df['review'])]#保留非null的review\nprint(df)\nd = {'cat':df['cat'].value_counts().index, 'count': df['cat'].value_counts()}#使用字典方法创建dataframe\ndf_cat = pd.DataFrame(data=d).reset_index(drop=True)#数据清洗时，会将带空值的行删除，此时DataFrame或Series类型的数据不再是连续的索引，可以使用reset_index()重置索引。\ndf_cat#查看重建完的dataframe\n\ndf['cat_id'] = df['cat'].factorize()[0]\ncat_id_df = df[['cat', 'cat_id']].drop_duplicates().sort_values('cat_id').reset_index(drop=True)\ncat_to_id = dict(cat_id_df.values)\nid_to_cat = dict(cat_id_df[['cat_id', 'cat']].values)\ndf.sample(10)\n\nimport re\nimport jieba as jb\ndef remove_punctuation(line):#使用正则表达式来过滤各种标点符号\n    line = str(line)\n    if line.strip()=='':\n        return ''\n    rule = re.compile(u\"[^a-zA-Z0-9\\u4E00-\\u9FA5]\")\n    line = rule.sub('',line)\n    return line\n \ndef stopwordslist(filepath): \n    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]  \n    return stopwords  \n    \nstopwords = stopwordslist(\"/kaggle/input/chinesestopwords/chineseStopWords.txt\")\n\ndf['clean_review'] = df['review'].apply(remove_punctuation)\n#df是pandas的series的数据结构,\ndf['cut_review'] = df['clean_review'].apply(lambda x: \" \".join([w for w in list(jb.cut(x)) if w not in stopwords]))\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-10T13:34:58.622162Z","iopub.execute_input":"2023-11-10T13:34:58.622756Z","iopub.status.idle":"2023-11-10T13:35:51.025523Z","shell.execute_reply.started":"2023-11-10T13:34:58.622694Z","shell.execute_reply":"2023-11-10T13:35:51.024597Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"数据总量: 62774 .\n在 cat 列中总共有 0 个空值.\n在 review 列中总共有 1 个空值.\n      cat                                             review\n0      书籍  ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...\n1      书籍  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...\n2      书籍  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...\n3      书籍  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...\n4      书籍  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...\n...    ..                                                ...\n62769  酒店  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...\n62770  酒店  房间很小，整体设施老化，和四星的差距很大。毛巾太破旧了。早餐很简陋。房间隔音很差，隔两间房间...\n62771  酒店                      我感觉不行。。。性价比很差。不知道是银川都这样还是怎么的！\n62772  酒店  房间时间长，进去有点异味！服务员是不是不够用啊！我在一楼找了半个小时以上才找到自己房间，想找...\n62773  酒店  老人小孩一大家族聚会，选在吴宫泛太平洋，以为新加坡品牌一定很不错，没想到11点30分到前台，...\n\n[62773 rows x 2 columns]\n","output_type":"stream"},{"name":"stderr","text":"Building prefix dict from the default dictionary ...\nDumping model to file cache /tmp/jieba.cache\nLoading model cost 1.260 seconds.\nPrefix dict has been built successfully.\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"  cat                                             review  cat_id  \\\n0  书籍  ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...       0   \n1  书籍  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...       0   \n2  书籍  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...       0   \n3  书籍  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...       0   \n4  书籍  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...       0   \n\n                                        clean_review  \\\n0  做父母一定要有刘墉这样的心态不断地学习不断地进步不断地给自己补充新鲜血液让自己保持一颗年轻的...   \n1  作者真有英国人严谨的风格提出观点进行论述论证尽管本人对物理学了解不深但是仍然能感受到真理的火...   \n2  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点为什么荷兰曾经县有欧洲最高的生产率...   \n3  作者在战几时之前用了拥抱令人叫绝日本如果没有战败就有会有美军的占领没胡官僚主义的延续没有战后...   \n4  作者在少年时即喜阅读能看出他精读了无数经典因而他有一个庞大的内心世界他的作品最难能可贵的有两...   \n\n                                          cut_review  \n0  做 父母 一定 刘墉 心态 不断 学习 不断 进步 不断 补充 新鲜血液 保持 一颗 年轻 ...  \n1  作者 真有 英国人 严谨 风格 提出 观点 进行 论述 论证 物理学 了解 不深 仍然 感受...  \n2  作者 长篇大论 借用 详细 报告 数据处理 工作 计算结果 支持 其新 观点 荷兰 曾经 县...  \n3  作者 战 之前 拥抱 令人 叫绝 日本 没有 战败 会 美军 占领 没胡 官僚主义 延续 没...  \n4  作者 少年 时即 喜 阅读 看出 精读 无数 经典 一个 庞大 内心世界 作品 难能可贵 两...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat</th>\n      <th>review</th>\n      <th>cat_id</th>\n      <th>clean_review</th>\n      <th>cut_review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>书籍</td>\n      <td>﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...</td>\n      <td>0</td>\n      <td>做父母一定要有刘墉这样的心态不断地学习不断地进步不断地给自己补充新鲜血液让自己保持一颗年轻的...</td>\n      <td>做 父母 一定 刘墉 心态 不断 学习 不断 进步 不断 补充 新鲜血液 保持 一颗 年轻 ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>书籍</td>\n      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n      <td>0</td>\n      <td>作者真有英国人严谨的风格提出观点进行论述论证尽管本人对物理学了解不深但是仍然能感受到真理的火...</td>\n      <td>作者 真有 英国人 严谨 风格 提出 观点 进行 论述 论证 物理学 了解 不深 仍然 感受...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>书籍</td>\n      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n      <td>0</td>\n      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点为什么荷兰曾经县有欧洲最高的生产率...</td>\n      <td>作者 长篇大论 借用 详细 报告 数据处理 工作 计算结果 支持 其新 观点 荷兰 曾经 县...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>书籍</td>\n      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n      <td>0</td>\n      <td>作者在战几时之前用了拥抱令人叫绝日本如果没有战败就有会有美军的占领没胡官僚主义的延续没有战后...</td>\n      <td>作者 战 之前 拥抱 令人 叫绝 日本 没有 战败 会 美军 占领 没胡 官僚主义 延续 没...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>书籍</td>\n      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n      <td>0</td>\n      <td>作者在少年时即喜阅读能看出他精读了无数经典因而他有一个庞大的内心世界他的作品最难能可贵的有两...</td>\n      <td>作者 少年 时即 喜 阅读 看出 精读 无数 经典 一个 庞大 内心世界 作品 难能可贵 两...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install tokenizer\n#文本预处理\nimport tokenizer\nfrom keras.preprocessing.text import Tokenizer\nfrom sklearn.metrics import recall_score, f1_score\n# 设置最频繁使用的50000个词\nMAX_NB_WORDS = 50000\n# 每条cut_review最大的长度\nMAX_SEQUENCE_LENGTH = 250\n# 设置Embeddingceng层的维度\nEMBEDDING_DIM = 100\n#num_words: 保留的最大词数，根据词频计算，保留前num_word - 1个\ntokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n#fit_on_texts（用以训练的已分过词的文本列表）\ntokenizer.fit_on_texts(df['cut_review'].values)\nword_index = tokenizer.word_index\nprint('共有 %s 个不相同的词语.' % len(word_index))\n# print(word_index)\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\nimport torch\nimport tensorflow as tf\n\ndevice = torch.device( 'cuda' if torch.cuda.is_available() else\n                      'cpu')\nprint(device)\n\nX = tokenizer.texts_to_sequences(df['cut_review'].values)\n#经过上一步操作后，X为整数构成的两层嵌套list\nX = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n#经过上步操作后，此时X变成了numpy.ndarray\n#多类标签的onehot展开\nY = pd.get_dummies(df['cat_id']).values\n\n# # 显存消失术！\n# train_ds = tf.data.Dataset.from_tensor_slices(\n#     (X, Y)).shuffle(20000).batch(32)\n# example_input_batch, example_target_batch = next(iter(train_ds))\n\n#修改分类的方法","metadata":{"execution":{"iopub.status.busy":"2023-11-10T13:35:51.027635Z","iopub.execute_input":"2023-11-10T13:35:51.027993Z","iopub.status.idle":"2023-11-10T13:36:19.892187Z","shell.execute_reply.started":"2023-11-10T13:35:51.027959Z","shell.execute_reply":"2023-11-10T13:36:19.891187Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting tokenizer\n  Downloading tokenizer-3.4.3-py2.py3-none-any.whl (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizer\nSuccessfully installed tokenizer-3.4.3\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"共有 70364 个不相同的词语.\ncuda\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi\n!ps aux|grep python ","metadata":{"execution":{"iopub.status.busy":"2023-11-10T13:36:19.893746Z","iopub.execute_input":"2023-11-10T13:36:19.894632Z","iopub.status.idle":"2023-11-10T13:36:21.908730Z","shell.execute_reply.started":"2023-11-10T13:36:19.894584Z","shell.execute_reply":"2023-11-10T13:36:21.907371Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Fri Nov 10 13:36:20 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   38C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\nroot           1  5.9  0.6 843904 208092 ?       Ssl  13:34   0:05 /opt/conda/bin/python3.10 /opt/conda/bin/jupyter-notebook --ip=* --NotebookApp.base_url=/k/150146119/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..tEra8HKIimCHjUjfRP2VwQ.enLI5NfQ4-VPVg75zeMtb61PduIhZXvY3u9hPR5nE_tT6rDNR2ogYGnJIhz4HGHNtyiy2koHHvgpyxB7d8AK2CmxxqQ5BsbvGzRejSkuaorgeKROELK-wNc0giT3RWjtO6-IV-jIGPG0nBE48IrhCAmXlIlNHV6870v7kzUf2qUjiIiCnWAHrw1u0o_boPjATkJD3jigv6xLJb5Gm8pAvA.QEz8sfl6bpW7_RqNqPSSUA/proxy/ --NotebookApp.token= --NotebookApp.notebook_dir=/kaggle/working --NotebookApp.allow_origin=* --NotebookApp.disable_check_xsrf=True --NotebookApp.iopub_data_rate_limit=10000000000 --NotebookApp.open_browser=False --NotebookApp.port=8888 --allow-root --MultiKernelManager.default_kernel_name=python3\nroot          10  0.1  0.0      0     0 ?        Z    13:34   0:00 [python] <defunct>\nroot          32 74.6  3.6 11324152 1194592 ?    Ssl  13:34   1:04 /opt/conda/bin/python3.10 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-d37f43a4-8984-4807-8c9f-3982d7711d7d.json\nroot          57  9.0  0.7 908252 252552 ?       Rl   13:34   0:07 /opt/conda/bin/python3.10 -m pylsp\nroot          90 44.2  1.0 2918420 341204 ?      Sl   13:36   0:02 /opt/conda/bin/python3.10 /opt/conda/lib/python3.10/site-packages/jedi/inference/compiled/subprocess/__main__.py /opt/conda/lib/python3.10/site-packages 3.10.12\nroot          97 85.0  0.0   4780  3152 pts/0    Ss+  13:36   0:00 /bin/bash -c ps aux|grep python\nroot          99  0.0  0.0   4024  1968 pts/0    S+   13:36   0:00 grep python\n","output_type":"stream"}]},{"cell_type":"code","source":"!kill -9 473","metadata":{"execution":{"iopub.status.busy":"2023-11-10T13:36:21.912608Z","iopub.execute_input":"2023-11-10T13:36:21.913034Z","iopub.status.idle":"2023-11-10T13:36:22.916442Z","shell.execute_reply.started":"2023-11-10T13:36:21.913001Z","shell.execute_reply":"2023-11-10T13:36:22.915207Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/bin/bash: line 1: kill: (473) - No such process\n","output_type":"stream"}]},{"cell_type":"code","source":"#RNN实现文本分类\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\n\nclass RNNCell(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(RNNCell, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n\n    def forward(self, x, h):\n        combined = torch.cat((x, h), 1)\n        h = torch.tanh(self.i2h(combined))\n        return h\n\nclass RNNNet(nn.Module):\n    def __init__(self, vocab_size, embedding_dim):\n        super(RNNNet, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.dropout = nn.Dropout(0.2)\n        self.rnn = RNNCell(embedding_dim, 100)\n        self.rnn.to(device)\n        self.fc = nn.Linear(100, 10)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = self.dropout(x)\n        h = torch.zeros(x.size(0), 100).to(x.device)\n        for i in range(x.size(1)):\n            h = self.rnn(x[:, i], h)\n        x = self.fc(h)\n        return x\n\n    # 定义模型\nmodel = RNNNet(50000, 100)\nprint(model)\nmodel.to(device)\n\n# 定义优化器和损失函数\noptimizer = Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n# 训练模型\nepochs = 5\nbatch_size = 512\n\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1)\nX_val, X_test, Y_val, Y_test = train_test_split(X_val, Y_val, test_size=0.5)\n\ntrain_data = DataLoader(list(zip(X_train, Y_train)), batch_size=batch_size)\nval_data = DataLoader(list(zip(X_val, Y_val)), batch_size=batch_size)\ntest_data = DataLoader(list(zip(X_test, Y_test)), batch_size=batch_size)\n\nfor epoch in range(epochs):\n    for i, (x, y) in enumerate(train_data):\n        x = x.to(device)\n        y = y.to(device)\n        optimizer.zero_grad()\n        output = model(x)\n        loss = criterion(output, torch.max(y, 1)[1])\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=10, norm_type=2)\n        optimizer.step()\n\n    with torch.no_grad():\n        val_loss = sum(criterion(model(x.to(device)), torch.max(y.to(device), 1)[1]) for x, y in val_data)\n        correct = 0\n        total = 0\n        for x, y in val_data:\n            x = x.to(device)\n            y = y.to(device)\n            outputs = model(x)\n            _, predicted = torch.max(outputs.data, 1)\n            _, y = torch.max(y.data, 1)\n            total += y.size(0)\n            correct += (predicted == y).sum().item()\n        accuracy = 100 * correct / total\n    print(f'Epoch: {epoch+1}, Loss: {loss.item()}, Val Loss: {val_loss.item()}, Accuracy: {accuracy}%')\n\n# 测试模型\nmodel.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    all_predicted = []\n    all_labels = []\n    for x, y in test_data:\n        x = x.to(device)\n        y = y.to(device)\n        outputs = model(x)\n        _, predicted = torch.max(outputs.data, 1)\n        _, y = torch.max(y.data, 1)\n        total += y.size(0)\n        correct += (predicted == y).sum().item()\n        all_predicted.extend(predicted.cpu().numpy())\n        all_labels.extend(y.cpu().numpy())\n    test_accuracy = 100 * correct / total\n    recall = recall_score(all_labels, all_predicted, average='macro')\n    f1 = f1_score(all_labels, all_predicted, average='macro')\nprint(f'Test Accuracy: {test_accuracy}%, Recall: {recall}, F1 Score: {f1}')","metadata":{"execution":{"iopub.status.busy":"2023-11-10T13:36:22.918016Z","iopub.execute_input":"2023-11-10T13:36:22.918320Z","iopub.status.idle":"2023-11-10T13:38:30.011711Z","shell.execute_reply.started":"2023-11-10T13:36:22.918291Z","shell.execute_reply":"2023-11-10T13:38:30.010576Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"RNNNet(\n  (embedding): Embedding(50000, 100)\n  (dropout): Dropout(p=0.2, inplace=False)\n  (rnn): RNNCell(\n    (i2h): Linear(in_features=200, out_features=100, bias=True)\n  )\n  (fc): Linear(in_features=100, out_features=10, bias=True)\n)\nEpoch: 1, Loss: 1.511783480644226, Val Loss: 10.948740005493164, Accuracy: 45.01433577572475%\nEpoch: 2, Loss: 1.040679931640625, Val Loss: 7.920699119567871, Accuracy: 60.210258043963044%\nEpoch: 3, Loss: 0.8805586695671082, Val Loss: 6.464482307434082, Accuracy: 68.1745778910481%\nEpoch: 4, Loss: 0.7921944856643677, Val Loss: 5.756990909576416, Accuracy: 71.55144950621217%\nEpoch: 5, Loss: 0.7301670908927917, Val Loss: 5.394140720367432, Accuracy: 73.20802803440586%\nTest Accuracy: 76.90347244345332%, Recall: 0.6503363837385961, F1 Score: 0.6442132711250034\n","output_type":"stream"}]},{"cell_type":"code","source":"#LSTM实现文本分类\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\n\nclass LSTMCell(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(LSTMCell, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.ii = nn.Linear(input_size, hidden_size)\n        self.hi = nn.Linear(hidden_size, hidden_size)\n        self.if_ = nn.Linear(input_size, hidden_size)\n        self.hf = nn.Linear(hidden_size, hidden_size)\n        self.ig = nn.Linear(input_size, hidden_size)\n        self.hg = nn.Linear(hidden_size, hidden_size)\n        self.io = nn.Linear(input_size, hidden_size)\n        self.ho = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, x, h, c):\n        i = torch.sigmoid(self.ii(x) + self.hi(h))\n        f = torch.sigmoid(self.if_(x) + self.hf(h))\n        g = torch.tanh(self.ig(x) + self.hg(h))\n        o = torch.sigmoid(self.io(x) + self.ho(h))\n        c = f * c + i * g\n        h = o * torch.tanh(c)\n        return h, c\n\nclass LSTMNet(nn.Module):\n    def __init__(self, vocab_size, embedding_dim):\n        super(LSTMNet, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.dropout = nn.Dropout(0.2)\n        self.lstm = LSTMCell(embedding_dim, 100)\n        self.lstm.to(device)\n        self.fc = nn.Linear(100, 10)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = self.dropout(x)\n        h = torch.zeros(x.size(0), 100).to(x.device)\n        c = torch.zeros(x.size(0), 100).to(x.device)\n        for i in range(x.size(1)):\n            h, c = self.lstm(x[:, i], h, c)\n        x = self.fc(h)\n        return x\n\n    # 定义模型\nmodel = LSTMNet(50000, 100)\nprint(model)\nmodel.to(device)\n\n# 定义优化器和损失函数\noptimizer = Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n# 训练模型\nepochs = 5\nbatch_size = 512\n\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1)\nX_val, X_test, Y_val, Y_test = train_test_split(X_val, Y_val, test_size=0.5)\n\ntrain_data = DataLoader(list(zip(X_train, Y_train)), batch_size=batch_size)\nval_data = DataLoader(list(zip(X_val, Y_val)), batch_size=batch_size)\ntest_data = DataLoader(list(zip(X_test, Y_test)), batch_size=batch_size)\n\nfor epoch in range(epochs):\n    for i, (x, y) in enumerate(train_data):\n        x = x.to(device)\n        y = y.to(device)\n        optimizer.zero_grad()\n        output = model(x)\n        loss = criterion(output, torch.max(y, 1)[1])\n        loss.backward()\n        optimizer.step()\n\n    with torch.no_grad():\n        val_loss = sum(criterion(model(x.to(device)), torch.max(y.to(device), 1)[1]) for x, y in val_data)\n        correct = 0\n        total = 0\n        for x, y in val_data:\n            x = x.to(device)\n            y = y.to(device)\n            outputs = model(x)\n            _, predicted = torch.max(outputs.data, 1)\n            _, y = torch.max(y.data, 1)\n            total += y.size(0)\n            correct += (predicted == y).sum().item()\n        accuracy = 100 * correct / total\n    print(f'Epoch: {epoch+1}, Loss: {loss.item()}, Val Loss: {val_loss.item()}, Accuracy: {accuracy}%')\n\n# 测试模型\nmodel.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    all_predicted = []\n    all_labels = []\n    for x, y in test_data:\n        x = x.to(device)\n        y = y.to(device)\n        outputs = model(x)\n        _, predicted = torch.max(outputs.data, 1)\n        _, y = torch.max(y.data, 1)\n        total += y.size(0)\n        correct += (predicted == y).sum().item()\n        all_predicted.extend(predicted.cpu().numpy())\n        all_labels.extend(y.cpu().numpy())\n    test_accuracy = 100 * correct / total\n    recall = recall_score(all_labels, all_predicted, average='macro')\n    f1 = f1_score(all_labels, all_predicted, average='macro')\nprint(f'Test Accuracy: {test_accuracy}%, Recall: {recall}, F1 Score: {f1}')","metadata":{"execution":{"iopub.status.busy":"2023-11-10T13:38:30.013401Z","iopub.execute_input":"2023-11-10T13:38:30.013770Z","iopub.status.idle":"2023-11-10T13:42:25.561719Z","shell.execute_reply.started":"2023-11-10T13:38:30.013740Z","shell.execute_reply":"2023-11-10T13:42:25.560612Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"LSTMNet(\n  (embedding): Embedding(50000, 100)\n  (dropout): Dropout(p=0.2, inplace=False)\n  (lstm): LSTMCell(\n    (ii): Linear(in_features=100, out_features=100, bias=True)\n    (hi): Linear(in_features=100, out_features=100, bias=True)\n    (if_): Linear(in_features=100, out_features=100, bias=True)\n    (hf): Linear(in_features=100, out_features=100, bias=True)\n    (ig): Linear(in_features=100, out_features=100, bias=True)\n    (hg): Linear(in_features=100, out_features=100, bias=True)\n    (io): Linear(in_features=100, out_features=100, bias=True)\n    (ho): Linear(in_features=100, out_features=100, bias=True)\n  )\n  (fc): Linear(in_features=100, out_features=10, bias=True)\n)\nEpoch: 1, Loss: 1.1835139989852905, Val Loss: 8.033931732177734, Accuracy: 61.61197833705002%\nEpoch: 2, Loss: 0.6093176603317261, Val Loss: 5.587780475616455, Accuracy: 74.57789104810449%\nEpoch: 3, Loss: 0.49713900685310364, Val Loss: 4.4804863929748535, Accuracy: 79.35648295635552%\nEpoch: 4, Loss: 0.3654424250125885, Val Loss: 3.9881691932678223, Accuracy: 81.0767760433259%\nEpoch: 5, Loss: 0.33157575130462646, Val Loss: 3.6888952255249023, Accuracy: 82.09620898375279%\nTest Accuracy: 83.49792927683976%, Recall: 0.7458874584038989, F1 Score: 0.7595972988337488\n","output_type":"stream"}]},{"cell_type":"code","source":"#GRU实现文本分类\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\n\nclass GRUCell(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(GRUCell, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.ir = nn.Linear(input_size, hidden_size)\n        self.hr = nn.Linear(hidden_size, hidden_size)\n        self.iz = nn.Linear(input_size, hidden_size)\n        self.hz = nn.Linear(hidden_size, hidden_size)\n        self.in_ = nn.Linear(input_size, hidden_size)\n        self.hn = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, x, h):\n        r = torch.sigmoid(self.ir(x) + self.hr(h))\n        z = torch.sigmoid(self.iz(x) + self.hz(h))\n        n = torch.tanh(self.in_(x) + r * self.hn(h))\n        h = (1 - z) * n + z * h\n        return h\n\nclass GRUNet(nn.Module):\n    def __init__(self, vocab_size, embedding_dim):\n        super(GRUNet, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.dropout = nn.Dropout(0.2)\n        self.gru = GRUCell(embedding_dim, 100)\n        self.gru.to(device)\n        self.fc = nn.Linear(100, 10)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = self.dropout(x)\n        h = torch.zeros(x.size(0), 100).to(x.device)\n        for i in range(x.size(1)):\n            h = self.gru(x[:, i], h)\n        x = self.fc(h)\n        return x\n    \n# 定义模型\nmodel = GRUNet(50000, 100)\nprint(model)\nmodel.to(device)\n\n# 定义优化器和损失函数\noptimizer = Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n# 训练模型\nepochs = 5\nbatch_size = 512\n\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1)\nX_val, X_test, Y_val, Y_test = train_test_split(X_val, Y_val, test_size=0.5)\n\ntrain_data = DataLoader(list(zip(X_train, Y_train)), batch_size=batch_size)\nval_data = DataLoader(list(zip(X_val, Y_val)), batch_size=batch_size)\ntest_data = DataLoader(list(zip(X_test, Y_test)), batch_size=batch_size)\n\nfor epoch in range(epochs):\n    for i, (x, y) in enumerate(train_data):\n        x = x.to(device)\n        y = y.to(device)\n        optimizer.zero_grad()\n        output = model(x)\n        loss = criterion(output, torch.max(y, 1)[1])\n        loss.backward()\n        optimizer.step()\n\n    with torch.no_grad():\n        val_loss = sum(criterion(model(x.to(device)), torch.max(y.to(device), 1)[1]) for x, y in val_data)\n        correct = 0\n        total = 0\n        for x, y in val_data:\n            x = x.to(device)\n            y = y.to(device)\n            outputs = model(x)\n            _, predicted = torch.max(outputs.data, 1)\n            _, y = torch.max(y.data, 1)\n            total += y.size(0)\n            correct += (predicted == y).sum().item()\n        accuracy = 100 * correct / total\n    print(f'Epoch: {epoch+1}, Loss: {loss.item()}, Val Loss: {val_loss.item()}, Accuracy: {accuracy}%')\n\n# 测试模型\nmodel.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    all_predicted = []\n    all_labels = []\n    for x, y in test_data:\n        x = x.to(device)\n        y = y.to(device)\n        outputs = model(x)\n        _, predicted = torch.max(outputs.data, 1)\n        _, y = torch.max(y.data, 1)\n        total += y.size(0)\n        correct += (predicted == y).sum().item()\n        all_predicted.extend(predicted.cpu().numpy())\n        all_labels.extend(y.cpu().numpy())\n    test_accuracy = 100 * correct / total\n    recall = recall_score(all_labels, all_predicted, average='macro')\n    f1 = f1_score(all_labels, all_predicted, average='macro')\nprint(f'Test Accuracy: {test_accuracy}%, Recall: {recall}, F1 Score: {f1}')","metadata":{"execution":{"iopub.status.busy":"2023-11-10T13:42:25.563281Z","iopub.execute_input":"2023-11-10T13:42:25.563599Z","iopub.status.idle":"2023-11-10T13:45:54.305439Z","shell.execute_reply.started":"2023-11-10T13:42:25.563573Z","shell.execute_reply":"2023-11-10T13:45:54.304155Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"GRUNet(\n  (embedding): Embedding(50000, 100)\n  (dropout): Dropout(p=0.2, inplace=False)\n  (gru): GRUCell(\n    (ir): Linear(in_features=100, out_features=100, bias=True)\n    (hr): Linear(in_features=100, out_features=100, bias=True)\n    (iz): Linear(in_features=100, out_features=100, bias=True)\n    (hz): Linear(in_features=100, out_features=100, bias=True)\n    (in_): Linear(in_features=100, out_features=100, bias=True)\n    (hn): Linear(in_features=100, out_features=100, bias=True)\n  )\n  (fc): Linear(in_features=100, out_features=10, bias=True)\n)\nEpoch: 1, Loss: 1.016778826713562, Val Loss: 7.599719047546387, Accuracy: 63.39598598279707%\nEpoch: 2, Loss: 0.5694119930267334, Val Loss: 4.480760097503662, Accuracy: 77.89104810449187%\nEpoch: 3, Loss: 0.4837716221809387, Val Loss: 3.604902744293213, Accuracy: 81.9369225868111%\nEpoch: 4, Loss: 0.37894222140312195, Val Loss: 3.278834819793701, Accuracy: 83.78464479133481%\nEpoch: 5, Loss: 0.33682793378829956, Val Loss: 2.9402248859405518, Accuracy: 85.5049378783052%\nTest Accuracy: 84.64479133482001%, Recall: 0.778310999648352, F1 Score: 0.7973575381943397\n","output_type":"stream"}]},{"cell_type":"code","source":"#Bi-LSTM进行文本分类\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\n\nclass LSTMCell(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(LSTMCell, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.ii = nn.Linear(input_size, hidden_size)\n        self.hi = nn.Linear(hidden_size, hidden_size)\n        self.if_ = nn.Linear(input_size, hidden_size)\n        self.hf = nn.Linear(hidden_size, hidden_size)\n        self.ig = nn.Linear(input_size, hidden_size)\n        self.hg = nn.Linear(hidden_size, hidden_size)\n        self.io = nn.Linear(input_size, hidden_size)\n        self.ho = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, x, h, c):\n        i = torch.sigmoid(self.ii(x) + self.hi(h))\n        f = torch.sigmoid(self.if_(x) + self.hf(h))\n        g = torch.tanh(self.ig(x) + self.hg(h))\n        o = torch.sigmoid(self.io(x) + self.ho(h))\n        c = f * c + i * g\n        h = o * torch.tanh(c)\n        return h, c\n\nclass BiLSTMNet(nn.Module):\n    def __init__(self, vocab_size, embedding_dim):\n        super(BiLSTMNet, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.dropout = nn.Dropout(0.2)\n        self.lstm = LSTMCell(embedding_dim, 100)\n        self.lstm.to(device)\n        self.lstm_rev = LSTMCell(embedding_dim, 100)\n        self.lstm_rev.to(device)\n        self.fc = nn.Linear(200, 10)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = self.dropout(x)\n        h = torch.zeros(x.size(0), 100).to(x.device)\n        c = torch.zeros(x.size(0), 100).to(x.device)\n        h_rev = torch.zeros(x.size(0), 100).to(x.device)\n        c_rev = torch.zeros(x.size(0), 100).to(x.device)\n        for i in range(x.size(1)):\n            h, c = self.lstm(x[:, i], h, c)\n            h_rev, c_rev = self.lstm_rev(x[:, x.size(1)-1-i], h_rev, c_rev)\n        h = torch.cat((h, h_rev), dim=1)\n        x = self.fc(h)\n        return x\n\n# 定义模型\nmodel = BiLSTMNet(50000, 100)\nprint(model)\nmodel.to(device)\n\n# 定义优化器和损失函数\noptimizer = Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n# 训练模型\nepochs = 5\nbatch_size = 512\n\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1)\nX_val, X_test, Y_val, Y_test = train_test_split(X_val, Y_val, test_size=0.5)\n\ntrain_data = DataLoader(list(zip(X_train, Y_train)), batch_size=batch_size)\nval_data = DataLoader(list(zip(X_val, Y_val)), batch_size=batch_size)\ntest_data = DataLoader(list(zip(X_test, Y_test)), batch_size=batch_size)\n\nfor epoch in range(epochs):\n    for i, (x, y) in enumerate(train_data):\n        x = x.to(device)\n        y = y.to(device)\n        optimizer.zero_grad()\n        output = model(x)\n        loss = criterion(output, torch.max(y, 1)[1])\n        loss.backward()\n        optimizer.step()\n\n    with torch.no_grad():\n        val_loss = sum(criterion(model(x.to(device)), torch.max(y.to(device), 1)[1]) for x, y in val_data)\n        correct = 0\n        total = 0\n        for x, y in val_data:\n            x = x.to(device)\n            y = y.to(device)\n            outputs = model(x)\n            _, predicted = torch.max(outputs.data, 1)\n            _, y = torch.max(y.data, 1)\n            total += y.size(0)\n            correct += (predicted == y).sum().item()\n        accuracy = 100 * correct / total\n    print(f'Epoch: {epoch+1}, Loss: {loss.item()}, Val Loss: {val_loss.item()}, Accuracy: {accuracy}%')\n\n# 测试模型\nmodel.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    all_predicted = []\n    all_labels = []\n    for x, y in test_data:\n        x = x.to(device)\n        y = y.to(device)\n        outputs = model(x)\n        _, predicted = torch.max(outputs.data, 1)\n        _, y = torch.max(y.data, 1)\n        total += y.size(0)\n        correct += (predicted == y).sum().item()\n        all_predicted.extend(predicted.cpu().numpy())\n        all_labels.extend(y.cpu().numpy())\n    test_accuracy = 100 * correct / total\n    recall = recall_score(all_labels, all_predicted, average='macro')\n    f1 = f1_score(all_labels, all_predicted, average='macro')\nprint(f'Test Accuracy: {test_accuracy}%, Recall: {recall}, F1 Score: {f1}')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-10T13:45:54.307453Z","iopub.execute_input":"2023-11-10T13:45:54.307853Z","iopub.status.idle":"2023-11-10T13:53:43.784010Z","shell.execute_reply.started":"2023-11-10T13:45:54.307811Z","shell.execute_reply":"2023-11-10T13:53:43.782738Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"BiLSTMNet(\n  (embedding): Embedding(50000, 100)\n  (dropout): Dropout(p=0.2, inplace=False)\n  (lstm): LSTMCell(\n    (ii): Linear(in_features=100, out_features=100, bias=True)\n    (hi): Linear(in_features=100, out_features=100, bias=True)\n    (if_): Linear(in_features=100, out_features=100, bias=True)\n    (hf): Linear(in_features=100, out_features=100, bias=True)\n    (ig): Linear(in_features=100, out_features=100, bias=True)\n    (hg): Linear(in_features=100, out_features=100, bias=True)\n    (io): Linear(in_features=100, out_features=100, bias=True)\n    (ho): Linear(in_features=100, out_features=100, bias=True)\n  )\n  (lstm_rev): LSTMCell(\n    (ii): Linear(in_features=100, out_features=100, bias=True)\n    (hi): Linear(in_features=100, out_features=100, bias=True)\n    (if_): Linear(in_features=100, out_features=100, bias=True)\n    (hf): Linear(in_features=100, out_features=100, bias=True)\n    (ig): Linear(in_features=100, out_features=100, bias=True)\n    (hg): Linear(in_features=100, out_features=100, bias=True)\n    (io): Linear(in_features=100, out_features=100, bias=True)\n    (ho): Linear(in_features=100, out_features=100, bias=True)\n  )\n  (fc): Linear(in_features=200, out_features=10, bias=True)\n)\nEpoch: 1, Loss: 1.2398053407669067, Val Loss: 8.193074226379395, Accuracy: 60.178400764574704%\nEpoch: 2, Loss: 0.81635582447052, Val Loss: 5.844939231872559, Accuracy: 70.88244663905702%\nEpoch: 3, Loss: 0.708685040473938, Val Loss: 4.638162136077881, Accuracy: 77.63618986938515%\nEpoch: 4, Loss: 0.5662342309951782, Val Loss: 3.9984140396118164, Accuracy: 80.82191780821918%\nEpoch: 5, Loss: 0.48988738656044006, Val Loss: 3.756101608276367, Accuracy: 81.42720611659765%\nTest Accuracy: 83.72093023255815%, Recall: 0.7506683175314238, F1 Score: 0.7617042759202175\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 第二部分\n## 使用GRU进行天气预测","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Dataset\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error, median_absolute_error\nimport matplotlib.pyplot as plt\n\ndevice = torch.device( 'cuda' if torch.cuda.is_available() else\n                      'cpu')\nprint(device)\n\n# 加载数据\ndata = pd.read_csv('/kaggle/input/jena-climate-from-2009-to-2016/jena_climate_2009_2016.csv')\ntemp = data['T (degC)'].values\n#print(temp)\n# 数据预处理\nscaler = MinMaxScaler(feature_range=(-10, 10))\nprint(\"tempreshape:\",temp.reshape(-1, 1))\ntemp = scaler.fit_transform(temp.reshape(-1, 1))\nprint(temp)\n\n# 划分数据集\ntrain_data = temp[:int(len(temp)*0.75)]\ntest_data = temp[int(len(temp)*0.75):]\n# train_data = torch.from_numpy(train_data)\n# test_data = torch.from_numpy(test_data)\n\n# 定义数据集\nclass TempDataset(Dataset):\n    def __init__(self, data, lookback=5*24*6, predict=2*24*6):\n        self.data = data\n        self.lookback = lookback\n        self.predict = predict\n\n    def __len__(self):\n        return len(self.data) - self.lookback - self.predict\n\n    def __getitem__(self, idx):\n        x = self.data[idx:idx+self.lookback]\n        y = self.data[idx+self.lookback:idx+self.lookback+self.predict]\n        return x, y\n\n# 定义模型\nclass GRUNet(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(GRUNet, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.sigmoid = nn.Sigmoid()\n        self.tanh = nn.Tanh()\n        self.fc_zr = nn.Linear(input_dim + hidden_dim, 2 * hidden_dim).to(device)\n        self.fc_n = nn.Linear(input_dim + hidden_dim, hidden_dim).to(device)\n        self.fc = nn.Linear(hidden_dim, output_dim).to(device)\n\n    def forward(self, x):\n        batch_size, seq_len, _ = x.size()\n        h = torch.zeros(batch_size, self.hidden_dim).to(x.device)\n        for t in range(seq_len):\n            x_t = x[:, t, :]\n            combined = torch.cat((x_t, h), dim=1)\n            z_r = self.sigmoid(self.fc_zr(combined))\n            z, r = torch.split(z_r, self.hidden_dim, dim=1)\n            combined_r = torch.cat((x_t, r * h), dim=1)\n            n = self.tanh(self.fc_n(combined_r))\n            h = (1 - z) * n + z * h\n        out = self.fc(h)\n        return out\n\n# 训练模型\nmodel = GRUNet(1, 100, 288)\nmodel.to(device)\ncriterion = nn.MSELoss()\noptimizer = Adam(model.parameters(), lr=0.01, weight_decay=0.0003)\n#optimizer = torch.optim.NAdam(model.parameters(), lr=0.01, weight_decay=0.001, momentum_decay=0.001, foreach=None)\n\ntrain_dataset = TempDataset(train_data)\ntrain_dataloader = DataLoader(train_dataset, batch_size=2048, shuffle=True)\n\n# for epoch in range(30):\n#     print(epoch)\n#     for i, (x, y) in enumerate(train_dataloader):\n#         x = x.float().to(device)\n#         #x = x.unsqueeze(-1)\n#         y = y.view(y.size(0), -1).float().to(device)\n#         #print(\"yshape:\",y.shape)\n#         optimizer.zero_grad()\n#         output = model(x)\n#         loss = criterion(output, y).float()\n#         loss.backward()\n#         optimizer.step()\n#     print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n\n# #保存模型\n# torch.save({'model': model.state_dict()}, '/kaggle/working/model.pth')\n\n## 读取模型\nmodel = GRUNet(1, 100, 288)\nstate_dict = torch.load('/kaggle/working/model.pth')\nmodel.load_state_dict(state_dict['model'])\n   \n# 测试模型\nmodel.eval()\nmodel.to(device)\ntest_dataset = TempDataset(test_data)\ntest_dataloader = DataLoader(test_dataset, batch_size=1)#一个batch代表5天的输入，两天的输出\n\nmaes = []\nmdaes = []\nfor i, (x, y) in enumerate(test_dataloader):\n    if i % 1000 == 0:\n        print(i)\n    if i >= 1500: #两个小时都没跑完，需要截断输出mae\n        break\n    #x = x.unsqueeze(-1)\n    x = x.to(device).float()\n    y = y.view(y.size(0), -1).to(device).float()\n    with torch.no_grad():\n        output = model(x)\n#     if i == 1:\n#         print(\"outputshape:\",output.shape)\n#         print(\"yshape:\",y.shape)\n    output = output.view(-1).cpu().numpy()\n    y = y.view(-1).cpu().numpy()\n#     if i == 1:\n#         print(\"outputshape:\",output.shape)\n#         print(\"yshape:\",y.shape)\n    #print(y.shape)\n    mae = mean_absolute_error(y, output)\n    mdae = median_absolute_error(y, output)\n    maes.append(mae)\n    mdaes.append(mdae)\n#     if i % 500 == 0:  # 每1000个样本画一次图\n#         plt.figure(figsize=(20, 4))\n#         plt.plot(y, label='True')\n#         plt.plot(output, label='Predict')\n#         plt.legend()\n#         plt.show()\n\nprint(f'Mean Absolute Error: {np.mean(maes)}, Median Absolute Error: {np.mean(mdaes)}')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T15:33:32.162585Z","iopub.execute_input":"2023-11-11T15:33:32.163404Z","iopub.status.idle":"2023-11-11T15:37:49.593507Z","shell.execute_reply.started":"2023-11-11T15:33:32.163371Z","shell.execute_reply":"2023-11-11T15:37:49.592411Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"cuda\ntempreshape: [[-8.02]\n [-8.41]\n [-8.51]\n ...\n [-3.16]\n [-4.23]\n [-4.82]]\n[[-5.02736772]\n [-5.15674241]\n [-5.18991541]\n ...\n [-3.41516006]\n [-3.77011113]\n [-3.96583181]]\n0\n1000\nMean Absolute Error: 1.1159099340438843, Median Absolute Error: 1.0005916357040405\n","output_type":"stream"}]}]}